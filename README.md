# ViLLa: Video Reasoning Segmentation with Large Language Model
[Rongkun Zheng](https://rkzheng99.github.io), [Lu Qi](http://luqi.info/), [Xi Chen](https://xavierchen34.github.io/), [Yi Wang](https://shepnerd.github.io/), Kun Wang, [Yu Qiao](https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=zh-CN&oi=ao), [Hengshuang Zhao*](https://hszhao.github.io/)

[[paper]](https://arxiv.org/abs/2407.14500) [[code]](https://github.com/rkzheng99/ViLLa) 

While previous studies have explored solutions to integrate reasoning with video segmentation through LLMs, they struggled to effectively model the **complex** scenes -- characterized by **multiple objects, rapid motion, heavy occlusions, and extended durations**. ViLLa, **Vi**deo reasoning segmentation with **L**arge **La**nguage Model, demonstrates capability in handling complex reasoning and referring video segmentation. Also, our model shows impressive ability in different temporal understanding benchmarks. 

### Illustrations of ViLLa. Our ViLLa is an effective and efficient LMM capable of segmenting and tracking: (a) multiple objects with rapid motion; (b) objects in crowded scenes; (c) objects in long videos with occlusions.
![image](https://github.com/rkzheng99/ViLLa/blob/rkzheng99-patch-1/pics/teaser.png)


### Visualization Results. Comparison between ViLLa and VISA.
![image](https://github.com/rkzheng99/ViLLa/blob/rkzheng99-patch-1/pics/illustration.png)

### Experiments
![image](https://github.com/rkzheng99/ViLLa/blob/rkzheng99-patch-1/pics/exp1.png)
Reasoning video segmentation results among ViLLa and previous related works on VideoReasonSeg benchmark. "Seg" refers to "Segmentation" while "MC" indicates "Multiple Choices".
