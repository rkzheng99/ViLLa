# ViLLa: Video Reasoning Segmentation with Large Language Model

[Rongkun Zheng](https://rkzheng99.github.io), [Lu Qi](http://luqi.info/), [Xi Chen](https://xavierchen34.github.io/), [Yi Wang](https://shepnerd.github.io/), Kun Wang, [Yu Qiao](https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=zh-CN&oi=ao), [Hengshuang Zhao*](https://hszhao.github.io/)

While previous studies have explored solutions to integrate reasoning with video segmentation through LLMs, they struggled to effectively model the **complex** scenes -- characterized by **multiple objects, rapid motion, heavy occlusions, and extended durations**. ViLLa demonstrates capability in handling complex reasoning and referring video segmentation. Also, our model shows impressive ability in different temporal understanding benchmarks. 

### Illustrations of ViLLa
![image](https://github.com/rkzheng99/ViLLa/blob/rkzheng99-patch-1/pics/teaser.png)

### Visualization Results
![image](https://github.com/rkzheng99/ViLLa/blob/rkzheng99-patch-1/pics/illustration.png)
